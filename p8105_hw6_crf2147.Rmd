---
title: "Homework 6"
author: "Charlotte Fowler"
date: "11/22/2019"
output: html_document
---

```{r}
library(tidyverse)
library(caret)
library(glmnet)
library(modelr)
library(mgcv)
```



# Problem 1 

```{r}
birthweight = read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(recode(babysex, "1" = "male", "2" = "female")), 
    frace = factor(recode(frace, "1" = "white", "2" = "black", "3" = "asian", "4" = "Puerto Rican", "8" = "other")), 
    mrace = factor(recode(mrace, "1" = "white", "2" = "black", "3" = "asian", "4" = "Puerto Rican", "8" = "other")), 
    malform = factor(recode(malform, "0" = "absent", "1" = "present")), 
  )


map_df(birthweight, function(x) any(is.na(x)))
```

There are no missing values.






First I will run LASSO to select the most important variables, with 10-fold cross validation. 
```{r}
#Using LASSO to try models
lambda <- 10^seq(-3, 3, length = 100)
set.seed(123)
lasso <- 
  train(
    bwt ~., 
    data = birthweight, 
    method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 1, lambda = lambda)
  )
# best coefficients
coef(lasso$finalModel, lasso$bestTune$lambda)
```

Because this model still includes 14 predictors, I will use backwards selection to choose the top 5 to include in my model. 

```{r}
#examining lasso model 
summary(lm(bwt~babysex + bhead + blength + delwt + fincome + frace + gaweeks + menarche + mheight + momage + mrace + parity + smoken + wtgain, data = birthweight))
```

Choosing coefficients in order of significance, we're left with head circumfrance, length, the mother's weight at delivery, the number of gestational weeks, and the average number of cigarettes smoked per day during the pregnancy. 
```{r}
#saving models
my_model = lm(bwt ~ bhead + blength + delwt + gaweeks + smoken, data = birthweight)

model2 = lm(bwt ~ blength + gaweeks, data = birthweight)

model3 = lm(bwt ~ bhead * babysex * blength, data = birthweight)
```


Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

```{r}
cv_df = 
  crossv_mc(birthweight, 100) 

cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))


cv_df = 
  cv_df %>% 
  mutate(my_mod  = map(train, ~lm(bwt ~ bhead + blength + delwt + gaweeks + smoken, data = .x)),
         mod2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         mod3  = map(train, ~lm(bwt ~ bhead * babysex * blength, data = .x))) %>% 
  mutate(rmse_my_mod = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
         rmse_mod3 = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)),
         rmse_mod3 = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)))
```



```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

From the graph above, we can see that my model, the first, has the lowest residual MSE, followed by the third model with interactions. However, there is not very much difference between these two models. The second model, with only the baby length and gestational age is by far the worst model. 



